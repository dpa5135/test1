from llama_cpp import Llama

# Load your local GGUF model
llm = Llama(model_path="D:/models/llama-3-8b-instruct.Q4_K_M.gguf", n_ctx=4096)

def check_fact_pattern_llm(utr_text, fact_pattern, llm):
    """
    Ask LLM if a fact pattern exists in the given UTR text.
    Returns 'Yes' or 'No' only.
    """
    prompt = f"""
You are a financial crime detection assistant.
Read the Unusual Transaction Report (UTR) text carefully.

Fact pattern to detect:
{fact_pattern}

Question:
Does this UTR text clearly describe or imply this fact pattern?

Respond with only one word:
"Yes" if the pattern is clearly or strongly implied.
"No" if the pattern is not present or unclear.

UTR Text:
\"\"\"{utr_text}\"\"\"
Answer:
"""

    response = llm(
        prompt,
        temperature=0.0,      # for deterministic output
        max_tokens=2,         # only need "Yes" or "No"
        stop=["\n"]
    )
    answer = response["choices"][0]["text"].strip().lower()
    if "yes" in answer:
        return "Yes"
    elif "no" in answer:
        return "No"
    else:
        return "No"

# Example usage
utr_example = "Customer made multiple cash deposits just below $10,000 over consecutive days."
fact_description = "Structuring: Breaking transactions into smaller amounts to avoid reporting thresholds."

result = check_fact_pattern_llm(utr_example, fact_description, llm)
print("LLM output:", result)

=====================================================================================================

schema = {
    "type": "object",
    "properties": {
        "fact_pattern_detected": {
            "type": "string",
            "enum": ["Yes", "No"]
        }
    },
    "required": ["fact_pattern_detected"]
}


response = llm.create_chat_completion(
    messages=[
        {"role": "system", "content": "You are a financial crime detection assistant."},
        {"role": "user", "content": f"""
UTR Text:
\"\"\"{utr_text}\"\"\"

Fact pattern: {fact_pattern}

Respond strictly in JSON matching this schema:
{schema}
"""}
    ],
    response_format={"type": "json_schema", "json_schema": schema},
    temperature=0.0,
)
print(response["choices"][0]["message"]["content"])
