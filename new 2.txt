from sklearn.feature_extraction.text import TfidfVectorizer

def extract_tfidf_keywords(corpus, top_k=10):
    vectorizer = TfidfVectorizer(stop_words='english')
    tfidf_matrix = vectorizer.fit_transform(corpus)
    feature_names = vectorizer.get_feature_names_out()

    keyword_list = []
    for i in range(len(corpus)):
        row = tfidf_matrix[i].toarray().flatten()
        top_indices = row.argsort()[-top_k:][::-1]
        top_keywords = [feature_names[idx] for idx in top_indices if row[idx] > 0]
        keyword_list.append(set(top_keywords))
    return keyword_list


def tfidf_keyword_coverage(summary, keywords):
    summary_words = set(summary.lower().split())
    matches = [k for k in keywords if k in summary_words]
    return len(matches) / len(keywords) if keywords else 0

# Precompute keyword sets
originals = df['V_COMMENTS'].fillna("").tolist()
tfidf_keywords = extract_tfidf_keywords(originals, top_k=10)

# Then for each row
for i, row in df.iterrows():
    summary = str(row['Brief Overview'])
    coverage = tfidf_keyword_coverage(summary, tfidf_keywords[i])
    # Save the coverage


